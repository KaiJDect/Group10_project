{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "58e63b1c-6d75-494e-b91e-7dc75b699fed",
      "metadata": {
        "id": "58e63b1c-6d75-494e-b91e-7dc75b699fed"
      },
      "source": [
        "**Data Inspection, Cleaning and Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqcbfOPFN1B2",
        "outputId": "32cfb9cc-75e0-48e4-e8c8-c8a59c210157"
      },
      "id": "mqcbfOPFN1B2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e6003f-f477-4631-b167-8ed6affb5289",
      "metadata": {
        "id": "c4e6003f-f477-4631-b167-8ed6affb5289"
      },
      "outputs": [],
      "source": [
        "# Import the necessary modules\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def df_check(df_to_check):\n",
        "    \"\"\"Function to generate information for a data frame\"\"\"\n",
        "    # Generate a summary for NaN, zero and unique values\n",
        "    nan_count = df_to_check.isna().sum()\n",
        "    unique_count = df_to_check.nunique()\n",
        "    zero_count = (df_to_check == 0).sum()\n",
        "    data_type = df_to_check.dtypes\n",
        "\n",
        "    # Merge the summaries into one dataframe for inspection\n",
        "    df_check = pd.concat([nan_count,unique_count, zero_count, data_type],axis =1)\n",
        "    df_check.columns = ['NaN Count','Unique Count','Zero Count', 'Data Type']\n",
        "    print(df_check)\n"
      ],
      "metadata": {
        "id": "_gsmOdstH1dd"
      },
      "id": "_gsmOdstH1dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load a CSV file into a DataFrame\n",
        "def load_csv(file_path, parse_dates=None, dtype=None):\n",
        "    \"\"\"Load a CSV file into a DataFrame.\"\"\"\n",
        "    return pd.read_csv(file_path, sep=',', header=0, parse_dates=parse_dates, dtype=dtype)\n"
      ],
      "metadata": {
        "id": "5eIP5oo9o4SI"
      },
      "id": "5eIP5oo9o4SI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess demand data (convert to datetime and aggregate)\n",
        "def preprocess_demand_data(df, date_format='%d/%m/%Y %H:%M', freq='D'):\n",
        "    \"\"\"Convert DATETIME to datetime format and aggregate the demand data by frequency.\"\"\"\n",
        "    df['DATETIME'] = pd.to_datetime(df['DATETIME'], format=date_format)\n",
        "    df.set_index('DATETIME', inplace=True)\n",
        "    df.drop('REGIONID', axis=1, inplace=True)\n",
        "    return df.resample(freq).sum()"
      ],
      "metadata": {
        "id": "A9iqoxDzpAFb"
      },
      "id": "A9iqoxDzpAFb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess temperature data (convert to datetime and calculate mean)\n",
        "def preprocess_temperature_data(df, date_format='%d/%m/%Y %H:%M', freq='D'):\n",
        "    \"\"\"Convert DATETIME to datetime format and calculate mean temperature by frequency.\"\"\"\n",
        "    df['DATETIME'] = pd.to_datetime(df['DATETIME'], format=date_format)\n",
        "    df.set_index('DATETIME', inplace=True)\n",
        "    df.drop('LOCATION', axis=1, inplace=True)\n",
        "    return df.resample(freq).mean()"
      ],
      "metadata": {
        "id": "SqaNu998pHsr"
      },
      "id": "SqaNu998pHsr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess SILO data\n",
        "def preprocess_silo_data(df, freq='D'):\n",
        "    \"\"\"Select relevant columns, calculate RH, and aggregate SILO data by frequency.\"\"\"\n",
        "    df['Date2'] = pd.to_datetime(df['Date2'], format='%d/%m/%Y')\n",
        "    df['RH'] = (df['RHmaxT'] + df['RHminT']) / 2  # Calculate RH as the average of RHMaxT and RHminT\n",
        "    df_filtered = df[['Date2', 'Rain', 'Evap', 'Radn', 'VP', 'RH']]  # Select relevant columns\n",
        "    df_filtered.set_index('Date2', inplace=True)\n",
        "\n",
        "    # Aggregating data based on frequency\n",
        "    if freq == 'D':\n",
        "        return df_filtered.resample(freq).mean()\n",
        "    else:\n",
        "        agg_dict = {\n",
        "            'Rain': 'sum',\n",
        "            'Evap': 'sum',\n",
        "            'Radn': 'sum',\n",
        "            'VP': 'sum',\n",
        "            'RH': 'mean'\n",
        "        }\n",
        "        return df_filtered.resample(freq).agg(agg_dict)"
      ],
      "metadata": {
        "id": "GR0bU4YDt9w7"
      },
      "id": "GR0bU4YDt9w7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform all preprocessing steps\n",
        "def preprocess_all_data(demand_file, temp_file, silo_file, demand_date_format, temp_date_format, freq='D'):\n",
        "    \"\"\"Load, preprocess demand, temperature, and SILO data.\"\"\"\n",
        "    # Load the data\n",
        "    demand_df = load_csv(demand_file, parse_dates=['DATETIME'], dtype={'TOTALDEMAND': float, 'REGIONID': str})\n",
        "    temp_df = load_csv(temp_file, parse_dates=['DATETIME'])\n",
        "    silo_df = load_csv(silo_file, parse_dates=['Date2'])\n",
        "\n",
        "    # Preprocess the data\n",
        "    demand_processed_df = preprocess_demand_data(demand_df, date_format=demand_date_format, freq=freq)\n",
        "    temp_processed_df = preprocess_temperature_data(temp_df, date_format=temp_date_format, freq=freq)\n",
        "    silo_processed_df = preprocess_silo_data(silo_df, freq=freq)\n",
        "\n",
        "    # Data Check\n",
        "    print(f\"Data check for {demand_file.split('/')[-1]}:\")\n",
        "    df_check(demand_processed_df)\n",
        "    print(\"\\n\")\n",
        "    print(f\"Data check for {temp_file.split('/')[-1]}:\")\n",
        "    df_check(temp_processed_df)\n",
        "    print(\"\\n\")\n",
        "    print(f\"Data check for {silo_file.split('/')[-1]}:\")\n",
        "    df_check(silo_processed_df)\n",
        "\n",
        "    return demand_processed_df, temp_processed_df, silo_processed_df"
      ],
      "metadata": {
        "id": "aD3woVj2pODG"
      },
      "id": "aD3woVj2pODG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the working directory\n",
        "os.chdir('/content/drive/MyDrive/data/Group10_project')\n",
        "\n",
        "# File paths\n",
        "nsw_demand_file = 'data/Raw Files/totaldemand_nsw.csv'\n",
        "qld_demand_file = 'data/Raw Files/totaldemand_qld.csv'\n",
        "nsw_temp_file = 'data/Raw Files/temperature_nsw.csv'\n",
        "qld_temp_file = 'data/Raw Files/temprature_qld.csv'\n",
        "nsw_silo_file = 'data/Raw Files/66137 BANKSTOWN.csv'\n",
        "qld_silo_file = 'data/Raw Files/40842 BRISBANE.csv'"
      ],
      "metadata": {
        "id": "BhYWAK8mpX3e"
      },
      "id": "BhYWAK8mpX3e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess NSW data\n",
        "daily_totaldemand_nsw, daily_temperature_nsw, daily_silo_nsw = preprocess_all_data(\n",
        "    nsw_demand_file, nsw_temp_file, nsw_silo_file, '%d/%m/%Y %H:%M', '%d/%m/%Y %H:%M', freq='D'\n",
        ")\n",
        "\n",
        "# Preprocess QLD data\n",
        "daily_totaldemand_qld, daily_temperature_qld, daily_silo_qld = preprocess_all_data(\n",
        "    qld_demand_file, qld_temp_file, qld_silo_file, '%d/%m/%Y %H:%M', '%d/%m/%Y %H:%M', freq='D'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsJ2vg5Vpbbn",
        "outputId": "d55fa35e-69d9-44f7-ba1f-b70d617df770"
      },
      "id": "PsJ2vg5Vpbbn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data check for totaldemand_nsw.csv:\n",
            "             NaN Count  Unique Count  Zero Count Data Type\n",
            "TOTALDEMAND          0          4095           0   float64\n",
            "\n",
            "\n",
            "Data check for temperature_nsw.csv:\n",
            "             NaN Count  Unique Count  Zero Count Data Type\n",
            "TEMPERATURE          3          3938           0   float64\n",
            "\n",
            "\n",
            "Data check for 66137 BANKSTOWN.csv:\n",
            "      NaN Count  Unique Count  Zero Count Data Type\n",
            "Rain          0           234        3592   float64\n",
            "Evap          0           129           1   float64\n",
            "Radn          0           327           0   float64\n",
            "VP            0           204           0   float64\n",
            "RH            0          1287           0   float64\n",
            "Data check for totaldemand_qld.csv:\n",
            "             NaN Count  Unique Count  Zero Count Data Type\n",
            "TOTALDEMAND          0          4094           0   float64\n",
            "\n",
            "\n",
            "Data check for temprature_qld.csv:\n",
            "             NaN Count  Unique Count  Zero Count Data Type\n",
            "TEMPERATURE          7          3767           0   float64\n",
            "\n",
            "\n",
            "Data check for 40842 BRISBANE.csv:\n",
            "      NaN Count  Unique Count  Zero Count Data Type\n",
            "Rain          0           243        3571   float64\n",
            "Evap          0           129          12   float64\n",
            "Radn          0           312           0   float64\n",
            "VP            0           238           0   float64\n",
            "RH            0          1312           0   float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate aggregates based on the dataframe columns and frequency\n",
        "def generate_aggregates(df, freq='W-MON'):\n",
        "    \"\"\"Generate aggregates based on frequency and available columns in the dataframe.\"\"\"\n",
        "    # Define the aggregation rules based on available columns in the dataframe\n",
        "    agg_dict = {}\n",
        "\n",
        "    # Check and add aggregation rules based on column presence\n",
        "    if 'Rain' in df.columns:\n",
        "        agg_dict['Rain'] = 'sum'\n",
        "    if 'Evap' in df.columns:\n",
        "        agg_dict['Evap'] = 'sum'\n",
        "    if 'Radn' in df.columns:\n",
        "        agg_dict['Radn'] = 'sum'\n",
        "    if 'VP' in df.columns:\n",
        "        agg_dict['VP'] = 'sum'\n",
        "    if 'RH' in df.columns:\n",
        "        agg_dict['RH'] = 'mean'\n",
        "    if 'TOTALDEMAND' in df.columns:\n",
        "        agg_dict['TOTALDEMAND'] = 'sum'\n",
        "    if 'TEMPERATURE' in df.columns:\n",
        "        agg_dict['TEMPERATURE'] = 'mean'\n",
        "\n",
        "    # If no specific aggregation rules are needed, just use sum for numeric columns\n",
        "    if not agg_dict:\n",
        "        return df.resample(freq).sum()\n",
        "\n",
        "    # Aggregate based on the defined aggregation rules\n",
        "    return df.resample(freq).agg(agg_dict)\n",
        "\n",
        "# Weekly aggregates\n",
        "weekly_totaldemand_nsw = generate_aggregates(daily_totaldemand_nsw, freq='W-MON')\n",
        "weekly_totaldemand_qld = generate_aggregates(daily_totaldemand_qld, freq='W-MON')\n",
        "weekly_temperature_nsw = generate_aggregates(daily_temperature_nsw, freq='W-MON')\n",
        "weekly_temperature_qld = generate_aggregates(daily_temperature_qld, freq='W-MON')\n",
        "weekly_silo_nsw = generate_aggregates(daily_silo_nsw, freq='W-MON')\n",
        "weekly_silo_qld = generate_aggregates(daily_silo_qld, freq='W-MON')\n",
        "\n",
        "# Monthly aggregates\n",
        "monthly_totaldemand_nsw = generate_aggregates(daily_totaldemand_nsw, freq='M')\n",
        "monthly_totaldemand_qld = generate_aggregates(daily_totaldemand_qld, freq='M')\n",
        "monthly_temperature_nsw = generate_aggregates(daily_temperature_nsw, freq='M')\n",
        "monthly_temperature_qld = generate_aggregates(daily_temperature_qld, freq='M')\n",
        "monthly_silo_nsw = generate_aggregates(daily_silo_nsw, freq='M')\n",
        "monthly_silo_qld = generate_aggregates(daily_silo_qld, freq='M')"
      ],
      "metadata": {
        "id": "AW_yI232qEN9"
      },
      "id": "AW_yI232qEN9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to merge demand, temperature, and SILO data\n",
        "def merge_dataframes(demand_df, temp_df, silo_df, join_type='left'):\n",
        "    \"\"\"\n",
        "    Merge demand, temperature, and SILO dataframes using the specified join type.\n",
        "    Arguments:\n",
        "    - demand_df: DataFrame containing demand data.\n",
        "    - temp_df: DataFrame containing temperature data.\n",
        "    - silo_df: DataFrame containing SILO data.\n",
        "    - join_type: Type of join to be used for merging (default is 'left').\n",
        "    Returns:\n",
        "    - merged_df: DataFrame with merged data.\n",
        "    \"\"\"\n",
        "    # Merge demand and temperature data\n",
        "    merged_df = demand_df.merge(temp_df, how=join_type, left_index=True, right_index=True)\n",
        "    # Merge the result with SILO data\n",
        "    merged_df = merged_df.merge(silo_df, how=join_type, left_index=True, right_index=True)\n",
        "    return merged_df\n",
        "\n",
        "# Merge daily data\n",
        "daily_merged_nsw = merge_dataframes(daily_totaldemand_nsw, daily_temperature_nsw, daily_silo_nsw)\n",
        "daily_merged_qld = merge_dataframes(daily_totaldemand_qld, daily_temperature_qld, daily_silo_qld)\n",
        "\n",
        "# Merge weekly data\n",
        "weekly_merged_nsw = merge_dataframes(weekly_totaldemand_nsw, weekly_temperature_nsw, weekly_silo_nsw)\n",
        "weekly_merged_qld = merge_dataframes(weekly_totaldemand_qld, weekly_temperature_qld, weekly_silo_qld)\n",
        "\n",
        "# Merge monthly data\n",
        "monthly_merged_nsw = merge_dataframes(monthly_totaldemand_nsw, monthly_temperature_nsw, monthly_silo_nsw)\n",
        "monthly_merged_qld = merge_dataframes(monthly_totaldemand_qld, monthly_temperature_qld, monthly_silo_qld)\n",
        "\n",
        "# Display the merged data (optional)\n",
        "print(\"Daily Merged NSW Data:\")\n",
        "print(daily_merged_nsw.head())\n",
        "\n",
        "print(\"\\nWeekly Merged NSW Data:\")\n",
        "print(weekly_merged_nsw.head())\n",
        "\n",
        "print(\"\\nMonthly Merged NSW Data:\")\n",
        "print(monthly_merged_nsw.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnDAJiaLxruF",
        "outputId": "3940f858-7c13-425d-e4c1-12106e6837a7"
      },
      "id": "rnDAJiaLxruF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daily Merged NSW Data:\n",
            "            TOTALDEMAND  TEMPERATURE  Rain  Evap  Radn    VP     RH\n",
            "DATETIME                                                           \n",
            "2010-01-01    374464.94    25.094000   0.2   5.2  14.6  23.1  76.35\n",
            "2010-01-02    384838.07    24.765385   0.0   5.9  18.4  22.0  67.80\n",
            "2010-01-03    355195.18    19.429825  15.2   1.9   7.3  19.1  83.25\n",
            "2010-01-04    395602.57    20.625926   0.2   3.4  14.4  18.2  75.15\n",
            "2010-01-05    423735.03    22.660417   0.0   6.8  28.1  16.9  65.35\n",
            "\n",
            "Weekly Merged NSW Data:\n",
            "            TOTALDEMAND  TEMPERATURE  Rain  Evap   Radn     VP         RH\n",
            "DATETIME                                                                 \n",
            "2010-01-04   1510100.76    22.478784  15.6  16.4   54.7   82.4  75.637500\n",
            "2010-01-11   3037003.89    23.787509   0.4  46.8  184.1  130.2  63.350000\n",
            "2010-01-18   3029758.51    22.719923   8.4  44.6  156.7  132.6  65.550000\n",
            "2010-01-25   3127293.47    23.591350   3.2  51.9  177.0  112.4  55.835714\n",
            "2010-02-01   3078396.21    23.982504  15.2  38.0  139.9  152.5  71.542857\n",
            "\n",
            "Monthly Merged NSW Data:\n",
            "            TOTALDEMAND  TEMPERATURE   Rain   Evap   Radn     VP         RH\n",
            "DATETIME                                                                   \n",
            "2010-01-31  13323429.31    23.361832   42.2  190.6  688.5  589.8  65.348387\n",
            "2010-02-28  12321216.04    23.198094  152.2  138.2  505.5  580.8  71.819643\n",
            "2010-03-31  12964117.30    21.474507   99.6  125.2  514.5  552.0  70.643548\n",
            "2010-04-30  11815599.71    18.048056   19.5   95.6  416.5  451.3  70.793333\n",
            "2010-05-31  13104176.57    14.396384   98.6   63.6  303.0  380.1  73.991935\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}